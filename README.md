## ëª©ì°¨
1. [Ullala GPT](#Ullala_GPT)
2. [ì²¨ë¶€ 01 :Document GPT](#ì²¨ë¶€ìë£Œ-01--document_gptpy-ì½”ë“œ-ì„¤ëª…)
3. [ì²¨ë¶€ 02 : Quiz GPT ì½”ë“œ](#ì²¨ë¶€-02--quiz-gpt-ì½”ë“œ)

# Ullala GPT

Document GPTëŠ” Streamlitì„ ì´ìš©í•´ ë§Œë“  ëŒ€í™”í˜• ë¬¸ì„œ ë¶„ì„ ì• í”Œë¦¬ì¼€ì´ì…˜ì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ AIì—ê²Œ ì§ˆë¬¸í•˜ê³  ë‹µë³€ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ê¸°ëŠ¥

1. **í™ˆ í˜ì´ì§€(app)**
   - ì• í”Œë¦¬ì¼€ì´ì…˜ì— ëŒ€í•œ ê¸°ë³¸ ì•ˆë‚´ ì œê³µ
   - ê°ê°ì˜ Tabì—ì„œ ê´€ë ¨ ì†ŒìŠ¤ ì½”ë“œ ì „ì²´ë¥¼ í™•ì¸ ê°€ëŠ¥

2. **Document GPT í˜ì´ì§€**
   - OpenAI API í‚¤ ì…ë ¥ ë° ìœ íš¨ì„± ê²€ì¦
   - ë¬¸ì„œ ì—…ë¡œë“œ (.txt, .pdf, .docx, .md íŒŒì¼ ì§€ì›)
   - ì—…ë¡œë“œëœ ë¬¸ì„œì— ëŒ€í•´ AIì—ê²Œ ì§ˆë¬¸í•˜ê³  ë‹µë³€ ë°›ê¸°

3. **Quiz GPT í˜ì´ì§€**
   - OpenAI API í‚¤ ì…ë ¥ ë° ìœ íš¨ì„± ê²€ì¦
   - WIKI ë˜ëŠ” íŒŒì¼ ì—…ë¡œë“œ ì„ íƒ ê°€ëŠ¥ 
   - WIKI ì„ íƒ ì‹œ í‚¤ì›Œë“œ ê²€ìƒ‰ì„ í†µí•´ í‚¤ì›Œë“œ ê´€ë ¨ í€´ì¦ˆ ì œê³µ(ë‚œì´ë„ ì„ íƒ ê°€ëŠ¥)
   - íŒŒì¼ ì—…ë¡œë“œ ì„ íƒ ì‹œ ì—…ë¡œë“œ ë¬¸ì„œ(.txt, .pdf, .docx, .md íŒŒì¼ ì§€ì›)ì— ë”°ë¥¸ í€´ì¦ˆ ì œê³µ

## ì„¤ì¹˜ ë° ì‹¤í–‰

1. ì €ì¥ì†Œë¥¼ í´ë¡ í•©ë‹ˆë‹¤:
   ```
   git clone [ì €ì¥ì†Œ URL]
   cd [í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬]
   ```

2. í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤:
   ```
   pip install -r requirements.txt
   ```

3. Streamlit ì•±ì„ ì‹¤í–‰í•©ë‹ˆë‹¤:
   ```
   streamlit run app.py
   ```

## íŒŒì¼ êµ¬ì¡°

```
.
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ app.py
â”œâ”€â”€ pages
â”‚   â”œâ”€â”€ Document_gpt.py
â”‚   â””â”€â”€ Quiz_gpt.py
â””â”€â”€ requirements.txt
```

- `app.py`: ë©”ì¸ Streamlit ì• í”Œë¦¬ì¼€ì´ì…˜ íŒŒì¼
- `pages/Document_gpt.py`: Document GPT ê¸°ëŠ¥ì„ êµ¬í˜„í•œ í˜ì´ì§€
- `pages/Quiz_gpt.py`: ì²¨ë¶€ë¬¸ì„œ ë˜ëŠ” ìœ„í‚¤ì˜ í‚¤ì›Œë“œ ê´€ë ¨ í€´ì¦ˆë¥¼ ì œê³µí•˜ëŠ” í˜ì´ì§€
- `requirements.txt`: í”„ë¡œì íŠ¸ ì˜ì¡´ì„± ëª©ë¡

## ì£¼ì˜ì‚¬í•­

- OpenAI API í‚¤ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì— ì €ì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
- ì§€ì›ë˜ëŠ” íŒŒì¼ í˜•ì‹: .txt, .pdf, .docx, .md

---
---

# ì²¨ë¶€ìë£Œ 01 : Document_gpt.py ì½”ë“œ ì„¤ëª…

## ëª©ì°¨
1. [ê°œìš”](#ê°œìš”)
2. [ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸](#ë¼ì´ë¸ŒëŸ¬ë¦¬-ì„í¬íŠ¸)
3. [ë¡œê¹… ì„¤ì •](#ë¡œê¹…-ì„¤ì •)
4. [Streamlit í˜ì´ì§€ ì„¤ì •](#streamlit-í˜ì´ì§€-ì„¤ì •)
5. [ChatCallbackHandler í´ë˜ìŠ¤](#chatcallbackhandler-í´ë˜ìŠ¤)
6. [OpenAI ëª¨ë¸ ì´ˆê¸°í™”](#openai-ëª¨ë¸-ì´ˆê¸°í™”)
7. [íŒŒì¼ ì„ë² ë”©](#íŒŒì¼-ì„ë² ë”©)
8. [ë©”ì‹œì§€ ê´€ë¦¬ í•¨ìˆ˜](#ë©”ì‹œì§€-ê´€ë¦¬-í•¨ìˆ˜)
9. [ë¬¸ì„œ í¬ë§·íŒ…](#ë¬¸ì„œ-í¬ë§·íŒ…)
10. [í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿](#í”„ë¡¬í”„íŠ¸-í…œí”Œë¦¿)
11. [API í‚¤ ê²€ì¦](#api-í‚¤-ê²€ì¦)
12. [ë©”ì¸ UI êµ¬ì„±](#ë©”ì¸-ui-êµ¬ì„±)
13. [ë©”ì¸ ë¡œì§](#ë©”ì¸-ë¡œì§)
14. [ê²°ë¡ ](#ê²°ë¡ )

## ê°œìš”

ì´ ì½”ë“œëŠ” Streamlitì„ ì‚¬ìš©í•˜ì—¬ ë§Œë“  "Document GPT" ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  í•´ë‹¹ ë¬¸ì„œì— ëŒ€í•´ ì§ˆë¬¸í•  ìˆ˜ ìˆìœ¼ë©°, OpenAIì˜ APIë¥¼ í™œìš©í•˜ì—¬ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.

## ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸

```python
import os
import requests
import logging
from langchain.prompts import ChatPromptTemplate
from langchain.document_loaders import UnstructuredFileLoader
from langchain.embeddings import CacheBackedEmbeddings, OpenAIEmbeddings
from langchain.schema.runnable import RunnableLambda, RunnablePassthrough
from langchain.storage import LocalFileStore
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores.faiss import FAISS
from langchain.chat_models import ChatOpenAI
from langchain.callbacks.base import BaseCallbackHandler
import streamlit as st
```

ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬:
- Streamlit: ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ì¶•
- LangChain: AI ëª¨ë¸ í™œìš©ì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬
- Requests: HTTP ìš”ì²­ ì²˜ë¦¬
- Logging: ë¡œê·¸ ê¸°ë¡

## ë¡œê¹… ì„¤ì •

```python
logging.basicConfig(
    level=logging.INFO,
    format='[%(levelname)s] %(message)s',
)
```

ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ë¡œê·¸ë¥¼ INFO ë ˆë²¨ë¡œ ì„¤ì •í•˜ê³ , ë¡œê·¸ í˜•ì‹ì„ ì§€ì •í•©ë‹ˆë‹¤.

## Streamlit í˜ì´ì§€ ì„¤ì •

```python
st.set_page_config(
    page_title="Document GPT",
    page_icon="ğŸ“„",
    layout="wide",
)
```

Streamlit ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ê¸°ë³¸ ì„¤ì •ì„ ì •ì˜í•©ë‹ˆë‹¤.

## ChatCallbackHandler í´ë˜ìŠ¤

```python
class ChatCallbackHandler(BaseCallbackHandler):
    def __init__(self):
        self.message = ""
        self.message_box = None

    def on_llm_start(self, *args, **kwargs):
        self.message_box = st.empty()

    def on_llm_end(self, *args, **kwargs):
        self.message = ""  # Reset the message after saving

    def on_llm_new_token(self, token, *args, **kwargs):
        self.message += token
        if self.message_box:
            self.message_box.markdown(self.message)
```

OpenAIì˜ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ì‹¤ì‹œê°„ìœ¼ë¡œ í™”ë©´ì— í‘œì‹œí•˜ê¸° ìœ„í•œ ì½œë°± í•¸ë“¤ëŸ¬ì…ë‹ˆë‹¤. í† í°ì´ ìƒì„±ë  ë•Œë§ˆë‹¤ ë©”ì‹œì§€ë¥¼ ì—…ë°ì´íŠ¸í•˜ê³  í‘œì‹œí•©ë‹ˆë‹¤.

## OpenAI ëª¨ë¸ ì´ˆê¸°í™”

```python
@st.cache_resource
def get_openai_model(api_key):
    return ChatOpenAI(
        temperature=0.1,
        streaming=True,
        callbacks=[ChatCallbackHandler()],
        openai_api_key=api_key,
    )
```

OpenAI ëª¨ë¸ì„ ì´ˆê¸°í™”í•˜ê³  ìºì‹±í•©ë‹ˆë‹¤. ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì‹œê°„ ì‘ë‹µì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.

## íŒŒì¼ ì„ë² ë”©

```python
@st.cache_data(show_spinner="Embedding File...")
def embed_file(file, api_key):
    # ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
    cache_dir = "./.cache"
    files_dir = os.path.join(cache_dir, "files")
    embeddings_dir = os.path.join(cache_dir, "embeddings")

    for dir_path in [cache_dir, files_dir, embeddings_dir]:
        if not os.path.exists(dir_path):
            os.makedirs(dir_path)
            logging.info(f"Created directory: {dir_path}")

    file_path = os.path.join(files_dir, file.name)
    logging.info(f'file_path: {file_path}')

    file_content = file.read()
    with open(file_path, "wb") as f:
        f.write(file_content)

    embeddings_store = LocalFileStore(os.path.join(embeddings_dir, file.name))
    splitter = CharacterTextSplitter.from_tiktoken_encoder(
        separator="\n",
        chunk_size=600,
        chunk_overlap=100,
    )
    loader = UnstructuredFileLoader(file_path)
    docs = loader.load_and_split(text_splitter=splitter)
    embeddings = OpenAIEmbeddings(openai_api_key=api_key)
    cached_embeddings = CacheBackedEmbeddings.from_bytes_store(
        embeddings, embeddings_store)
    vectorstore = FAISS.from_documents(docs, cached_embeddings)
    retriever = vectorstore.as_retriever()
    return retriever
```

ì—…ë¡œë“œëœ íŒŒì¼ì„ ì²˜ë¦¬í•˜ê³  ì„ë² ë”©í•©ë‹ˆë‹¤. ìºì‹œ ë””ë ‰í† ë¦¬ë¥¼ ìƒì„±í•˜ê³  ê´€ë¦¬í•©ë‹ˆë‹¤. íŒŒì¼ì„ ì²­í¬ë¡œ ë¶„í• í•˜ê³ , ì„ë² ë”©ì„ ìƒì„±í•œ í›„ FAISS ë²¡í„° ì €ì¥ì†Œì— ì €ì¥í•©ë‹ˆë‹¤.

## ë©”ì‹œì§€ ê´€ë¦¬ í•¨ìˆ˜

```python
def save_message(message, role):
    # Remove 'content=' prefix if it exists
    if message.startswith("content='") and message.endswith("'"):
        # Remove the first 9 characters and the last character
        message = message[9:-1]
    st.session_state["messages"].append({"message": message, "role": role})

def send_message(message, role, save=True):
    with st.chat_message(role):
        if role == "ai":
            st.empty().markdown(message)
        else:
            st.markdown(message)
    if save:
        save_message(message, role)

def paint_history():
    for message in st.session_state["messages"]:
        send_message(message["message"], message["role"], save=False)
```

ì±„íŒ… íˆìŠ¤í† ë¦¬ë¥¼ ê´€ë¦¬í•˜ëŠ” í•¨ìˆ˜ë“¤ì…ë‹ˆë‹¤. `save_message`ëŠ” ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥í•˜ê³ , `send_message`ëŠ” ë©”ì‹œì§€ë¥¼ í™”ë©´ì— í‘œì‹œí•©ë‹ˆë‹¤. `paint_history`ëŠ” ì €ì¥ëœ ëª¨ë“  ë©”ì‹œì§€ë¥¼ í™”ë©´ì— ë‹¤ì‹œ ê·¸ë¦½ë‹ˆë‹¤.

## ë¬¸ì„œ í¬ë§·íŒ…

```python
def format_docs(docs):
    return "\n\n".join(document.page_content for document in docs)
```

ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤.

## í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿

```python
prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            """
            Answer the question using ONLY the following context. If you don't know the answer just say you don't know. DON'T make anything up.
            
            Context: {context}
            """,
        ),
        ("human", "{question}"),
    ]
)
```

AIì—ê²Œ ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ì˜ êµ¬ì¡°ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ì‚¬ìš©ì ì§ˆë¬¸ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.

## API í‚¤ ê²€ì¦

```python
def is_valid_api_key(api_key):
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    try:
        response = requests.get(
            "https://api.openai.com/v1/models", headers=headers)
        return response.status_code == 200
    except requests.RequestException:
        return False
```

ì œê³µëœ OpenAI API í‚¤ì˜ ìœ íš¨ì„±ì„ ê²€ì‚¬í•©ë‹ˆë‹¤. OpenAIì˜ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸ë¥¼ í˜¸ì¶œí•˜ì—¬ í™•ì¸í•©ë‹ˆë‹¤.

## ë©”ì¸ UI êµ¬ì„±

```python
st.title("ğŸ“„ Document GPT")

st.markdown("í™˜ì˜í•©ë‹ˆë‹¤!<br>ì´ ì±—ë´‡ì„ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ì„ ì—…ë¡œë“œ í•˜ê³  AIì—ê²Œ ì§ˆë¬¸í•˜ì„¸ìš”!<br>ì‚¬ì´ë“œ ë°”ì— API í‚¤ë¥¼ ì…ë ¥í•˜ê³  íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”!<br>API í‚¤ëŠ” ì €ì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
            unsafe_allow_html=True)

with st.sidebar:
    api_key = st.text_input("OpenAI API Key", type="password")
    file = st.file_uploader("Upload a .txt, .pdf, .docs, .md files only", type=[
                            "pdf", "txt", "docx", "md"])
```

ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ë©”ì¸ UIë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤. ì œëª©, ì„¤ëª…, API í‚¤ ì…ë ¥ í•„ë“œ, íŒŒì¼ ì—…ë¡œë”ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.

## ë©”ì¸ ë¡œì§

```python
if api_key:
    if is_valid_api_key(api_key):
        os.environ["OPENAI_API_KEY"] = api_key
        st.success("API í‚¤ê°€ ìœ íš¨í•©ë‹ˆë‹¤.")

        if file:
            try:
                retriever = embed_file(file, api_key)
                llm = get_openai_model(api_key)
                send_message("Good! Ask Anything!", "ai", save=False)
                paint_history()
                message = st.chat_input("Ask Anything! about your file...")
                if message:
                    send_message(message, "human")
                    chain = ({
                        "context": retriever | RunnableLambda(format_docs),
                        "question": RunnablePassthrough(),
                    } | prompt | llm)
                    with st.chat_message("ai"):
                        response = chain.invoke(message)
                        save_message(response.content, "ai")
            except Exception as e:
                st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                logging.error(
                    f"Error processing file: {str(e)}", exc_info=True)
        else:
            st.warning("Please upload a file in the sidebar.")
    else:
        st.error("Invalid API key. Please check your OpenAI API key and try again.")
elif not api_key:
    st.warning("Please enter your OpenAI API key in the sidebar.")

if "messages" not in st.session_state:
    st.session_state["messages"] = []
```

ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì£¼ìš” ë¡œì§ì„ êµ¬í˜„í•©ë‹ˆë‹¤:
1. API í‚¤ ìœ íš¨ì„± ê²€ì‚¬
2. íŒŒì¼ ì—…ë¡œë“œ ë° ì²˜ë¦¬
3. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
4. AI ì‘ë‹µ ìƒì„± ë° í‘œì‹œ
5. ì˜¤ë¥˜ ì²˜ë¦¬ ë° ë¡œê¹…

ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥í•˜ì—¬ ëŒ€í™”ì˜ ì—°ì†ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤.

## ê²°ë¡ 

ì´ Document GPT ì• í”Œë¦¬ì¼€ì´ì…˜ì€ Streamlitê³¼ LangChainì„ í™œìš©í•˜ì—¬ ë³µì¡í•œ AI ê¸°ëŠ¥ì„ ê°„ë‹¨í•œ ì›¹ ì¸í„°í˜ì´ìŠ¤ë¡œ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤. ì£¼ìš” íŠ¹ì§•ìœ¼ë¡œëŠ” ì‹¤ì‹œê°„ ì‘ë‹µ, ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸ë‹µë³€, API í‚¤ ë³´ì•ˆ, íš¨ìœ¨ì ì¸ íŒŒì¼ ì²˜ë¦¬, ê·¸ë¦¬ê³  í–¥ìƒëœ ì˜¤ë¥˜ ì²˜ë¦¬ ë° ë¡œê¹…ì´ ìˆìŠµë‹ˆë‹¤. ì´ ì• í”Œë¦¬ì¼€ì´ì…˜ì€ ì‚¬ìš©ì ì¹œí™”ì ì¸ ì¸í„°í˜ì´ìŠ¤ì™€ ê°•ë ¥í•œ AI ê¸°ëŠ¥ì„ ê²°í•©í•˜ì—¬ ë¬¸ì„œ ë¶„ì„ ë° ì •ë³´ ì¶”ì¶œ ì‘ì—…ì„ íš¨ê³¼ì ìœ¼ë¡œ ìˆ˜í–‰í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.

---
---

# ì²¨ë¶€ 02 : Quiz GPT ì½”ë“œ

## ëª©ì°¨
1. [ê°œìš”](#ê°œìš”)
2. [í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬](#í™˜ê²½-ì„¤ì •-ë°-ë¼ì´ë¸ŒëŸ¬ë¦¬)
3. [ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤ ë° í•¨ìˆ˜](#ìœ í‹¸ë¦¬í‹°-í´ë˜ìŠ¤-ë°-í•¨ìˆ˜)
4. [OpenAI ëª¨ë¸ êµ¬ì„±](#openai-ëª¨ë¸-êµ¬ì„±)
5. [ë¬¸ì„œ ì²˜ë¦¬ ê¸°ëŠ¥](#ë¬¸ì„œ-ì²˜ë¦¬-ê¸°ëŠ¥)
6. [ìœ„í‚¤í”¼ë””ì•„ í†µí•©](#ìœ„í‚¤í”¼ë””ì•„-í†µí•©)
7. [í€´ì¦ˆ ìƒì„± ì—”ì§„](#í€´ì¦ˆ-ìƒì„±-ì—”ì§„)
8. [í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§](#í”„ë¡¬í”„íŠ¸-ì—”ì§€ë‹ˆì–´ë§)
9. [ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ ì„¤ê³„](#ì‚¬ìš©ì-ì¸í„°í˜ì´ìŠ¤-ì„¤ê³„)
10. [ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œì§](#ë©”ì¸-ì• í”Œë¦¬ì¼€ì´ì…˜-ë¡œì§)
11. [ì˜¤ë¥˜ ì²˜ë¦¬ ë° ë¡œê¹…](#ì˜¤ë¥˜-ì²˜ë¦¬-ë°-ë¡œê¹…)
12. [ì„±ëŠ¥ ìµœì í™”](#ì„±ëŠ¥-ìµœì í™”)
13. [ê²°ë¡  ë° í–¥í›„ ê°œì„  ì‚¬í•­](#ê²°ë¡ -ë°-í–¥í›„-ê°œì„ -ì‚¬í•­)

## 1. ê°œìš”

Quiz GPTëŠ” Streamlitì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ëŒ€í™”í˜• ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ìœ¼ë¡œ, OpenAIì˜ GPT-4 ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ë™ì ìœ¼ë¡œ í€´ì¦ˆë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì‚¬ìš©ìëŠ” ìœ„í‚¤í”¼ë””ì•„ ì£¼ì œë¥¼ ê²€ìƒ‰í•˜ê±°ë‚˜ ì§ì ‘ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ë‹¤ì–‘í•œ ì£¼ì œì— ëŒ€í•œ í€´ì¦ˆë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ì• í”Œë¦¬ì¼€ì´ì…˜ì€ êµìœ¡ ëª©ì  ë° ì—”í„°í…Œì¸ë¨¼íŠ¸ìš©ìœ¼ë¡œ ì„¤ê³„ë˜ì—ˆìœ¼ë©°, ì‚¬ìš©ì ì§€ì • ë‚œì´ë„ ì„¤ì •ì„ ì§€ì›í•©ë‹ˆë‹¤.

## 2. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬

```python
import json
import os
import requests
import logging
import wikipedia
from langchain.document_loaders import UnstructuredFileLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.callbacks import StreamingStdOutCallbackHandler
import streamlit as st
from langchain.schema import BaseOutputParser, Document

logging.basicConfig(level=logging.INFO, format='[%(levelname)s] %(message)s')
```

ì´ ì„¹ì…˜ì—ì„œëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì— í•„ìš”í•œ ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„í¬íŠ¸í•©ë‹ˆë‹¤:

- `json`: JSON ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤.
- `os`: ìš´ì˜ ì²´ì œ ê´€ë ¨ ê¸°ëŠ¥(ì˜ˆ: íŒŒì¼ ê²½ë¡œ ì¡°ì‘)ì— ì‚¬ìš©ë©ë‹ˆë‹¤.
- `requests`: HTTP ìš”ì²­ì„ ë³´ë‚´ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤(API í‚¤ ê²€ì¦ ë“±).
- `logging`: ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œê¹…ì„ ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤.
- `wikipedia`: ìœ„í‚¤í”¼ë””ì•„ APIì™€ ìƒí˜¸ ì‘ìš©í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤.
- LangChain ê´€ë ¨ ì„í¬íŠ¸:
  - `UnstructuredFileLoader`: ë‹¤ì–‘í•œ í˜•ì‹ì˜ íŒŒì¼ì„ ë¡œë“œí•˜ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤.
  - `CharacterTextSplitter`: ê¸´ í…ìŠ¤íŠ¸ë¥¼ ê´€ë¦¬ ê°€ëŠ¥í•œ ì²­í¬ë¡œ ë¶„í• í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤.
  - `ChatOpenAI`: OpenAIì˜ ì±„íŒ… ëª¨ë¸ê³¼ ìƒí˜¸ ì‘ìš©í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤.
  - `ChatPromptTemplate`: êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤.
  - `StreamingStdOutCallbackHandler`: ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤.
- `streamlit`: ì›¹ ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬ì¶•í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤.

ë¡œê¹… ì„¤ì •ì€ INFO ë ˆë²¨ë¡œ êµ¬ì„±ë˜ì–´ ìˆì–´, ì¤‘ìš”í•œ ì´ë²¤íŠ¸ì™€ ì˜¤ë¥˜ë¥¼ ì½˜ì†”ì— ì¶œë ¥í•©ë‹ˆë‹¤.

## 3. ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤ ë° í•¨ìˆ˜

### JsonOutputParser í´ë˜ìŠ¤

```python
class JsonOutputParser(BaseOutputParser):
    def parse(self, text):
        text = text.replace("```", "").replace("json", "")
        return json.loads(text)

output_parser = JsonOutputParser()
```

ì´ í´ë˜ìŠ¤ëŠ” LangChainì˜ `BaseOutputParser`ë¥¼ ìƒì†ë°›ì•„ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤:
- `parse` ë©”ì„œë“œëŠ” AI ëª¨ë¸ì˜ ì¶œë ¥ì„ ì •ì œí•˜ê³  JSONìœ¼ë¡œ íŒŒì‹±í•©ë‹ˆë‹¤.
- ì½”ë“œ ë¸”ë¡ êµ¬ë¶„ì(`"""`)ì™€ 'json' í‚¤ì›Œë“œë¥¼ ì œê±°í•˜ì—¬ ìˆœìˆ˜í•œ JSON ë¬¸ìì—´ë§Œ ë‚¨ê¹ë‹ˆë‹¤.
- `json.loads()`ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ìì—´ì„ Python ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
- ì´ íŒŒì„œëŠ” AI ëª¨ë¸ì˜ êµ¬ì¡°í™”ëœ ì¶œë ¥ì„ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.

### API í‚¤ ê²€ì¦ í•¨ìˆ˜

```python
def is_valid_api_key(api_key):
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    try:
        response = requests.get(
            "https://api.openai.com/v1/models", headers=headers)
        return response.status_code == 200
    except requests.RequestException:
        return False
```

ì´ í•¨ìˆ˜ëŠ” ì‚¬ìš©ìê°€ ì…ë ¥í•œ OpenAI API í‚¤ì˜ ìœ íš¨ì„±ì„ ê²€ì‚¬í•©ë‹ˆë‹¤:
- OpenAI APIì˜ '/v1/models' ì—”ë“œí¬ì¸íŠ¸ì— GET ìš”ì²­ì„ ë³´ëƒ…ë‹ˆë‹¤.
- ìœ íš¨í•œ API í‚¤ì˜ ê²½ìš° 200 ìƒíƒœ ì½”ë“œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
- ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ë‚˜ ì˜ëª»ëœ API í‚¤ì˜ ê²½ìš° Falseë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
- ì´ ê²€ì¦ ê³¼ì •ì€ ì‚¬ìš©ì ê²½í—˜ì„ í–¥ìƒì‹œí‚¤ê³ , ì˜ëª»ëœ API í‚¤ë¡œ ì¸í•œ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.

## 4. OpenAI ëª¨ë¸ êµ¬ì„±

```python
@st.cache_resource
def get_openai_model(api_key):
    return ChatOpenAI(
        temperature=0.1,
        model="gpt-4-0613",
        streaming=True,
        callbacks=[StreamingStdOutCallbackHandler()],
        openai_api_key=api_key,
    )
```

ì´ í•¨ìˆ˜ëŠ” OpenAIì˜ GPT-4 ëª¨ë¸ì„ ì´ˆê¸°í™”í•˜ê³  êµ¬ì„±í•©ë‹ˆë‹¤:
- `@st.cache_resource` ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìºì‹œí•©ë‹ˆë‹¤. ì´ëŠ” ë°˜ë³µì ì¸ ëª¨ë¸ ì´ˆê¸°í™”ë¥¼ ë°©ì§€í•˜ì—¬ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
- `temperature=0.1`: ë‚®ì€ temperature ê°’ì„ ì„¤ì •í•˜ì—¬ ëª¨ë¸ì˜ ì¶œë ¥ì„ ë” ê²°ì •ì ì´ê³  ì¼ê´€ë˜ê²Œ ë§Œë“­ë‹ˆë‹¤.
- `model="gpt-4-0613"`: GPT-4 ëª¨ë¸ì˜ íŠ¹ì • ë²„ì „ì„ ì§€ì •í•©ë‹ˆë‹¤.
- `streaming=True`: ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œë¥¼ í™œì„±í™”í•˜ì—¬ ì‹¤ì‹œê°„ìœ¼ë¡œ ì‘ë‹µì„ ë°›ìŠµë‹ˆë‹¤.
- `callbacks=[StreamingStdOutCallbackHandler()]`: ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ í‘œì¤€ ì¶œë ¥ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
- ì‚¬ìš©ìì˜ API í‚¤ë¥¼ ëª¨ë¸ êµ¬ì„±ì— í¬í•¨ì‹œí‚µë‹ˆë‹¤.

## 5. ë¬¸ì„œ ì²˜ë¦¬ ê¸°ëŠ¥

```python
@st.cache_data(show_spinner="íŒŒì¼ ë¡œë”© ì¤‘...")
def split_file(file):
    file_content = file.read()
    cache_dir = "./.cache/quiz_files"
    if not os.path.exists(cache_dir):
        os.makedirs(cache_dir)
        logging.info(f"ë””ë ‰í† ë¦¬ ìƒì„±: {cache_dir}")
    file_path = os.path.join(cache_dir, file.name)
    with open(file_path, "wb") as f:
        f.write(file_content)
    logging.info(f"íŒŒì¼ ì €ì¥: {file_path}")
    splitter = CharacterTextSplitter.from_tiktoken_encoder(
        separator="\n",
        chunk_size=600,
        chunk_overlap=100,
    )
    loader = UnstructuredFileLoader(file_path)
    docs = loader.load_and_split(text_splitter=splitter)
    return docs
```

ì´ í•¨ìˆ˜ëŠ” ì—…ë¡œë“œëœ íŒŒì¼ì„ ì²˜ë¦¬í•˜ê³  ë¶„í• í•©ë‹ˆë‹¤:
- `@st.cache_data` ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì²˜ë¦¬ ê²°ê³¼ë¥¼ ìºì‹œí•©ë‹ˆë‹¤. ì´ëŠ” ë™ì¼í•œ íŒŒì¼ì— ëŒ€í•œ ì¤‘ë³µ ì²˜ë¦¬ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
- ì—…ë¡œë“œëœ íŒŒì¼ì„ ë¡œì»¬ ìºì‹œ ë””ë ‰í† ë¦¬ì— ì €ì¥í•©ë‹ˆë‹¤.
- `CharacterTextSplitter`ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œë¥¼ ê´€ë¦¬ ê°€ëŠ¥í•œ ì²­í¬ë¡œ ë¶„í• í•©ë‹ˆë‹¤:
  - `chunk_size=600`: ê° ì²­í¬ì˜ ìµœëŒ€ í¬ê¸°ë¥¼ 600ìë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
  - `chunk_overlap=100`: ì²­í¬ ê°„ 100ì ì˜¤ë²„ë©ì„ í—ˆìš©í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ ìœ ì§€ë¥¼ ë³´ì¥í•©ë‹ˆë‹¤.
- `UnstructuredFileLoader`ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ì–‘í•œ íŒŒì¼ í˜•ì‹(.docx, .txt, .pdf, .md)ì„ ì§€ì›í•©ë‹ˆë‹¤.
- ë¶„í• ëœ ë¬¸ì„œ ì²­í¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

## 6. ìœ„í‚¤í”¼ë””ì•„ í†µí•©

```python
@st.cache_data(show_spinner="ìœ„í‚¤í”¼ë””ì•„ ê²€ìƒ‰ ì¤‘...")
def wiki_search(term):
    try:
        try:
            page = wikipedia.page(term)
            return [{"page_content": page.content, "metadata": {"title": page.title}}]
        except wikipedia.exceptions.DisambiguationError as e:
            page = wikipedia.page(e.options[0])
            return [{"page_content": page.content, "metadata": {"title": page.title}}]
        except wikipedia.exceptions.PageError:
            search_results = wikipedia.search(term, results=1)
            if not search_results:
                return []
            page = wikipedia.page(search_results[0])
            return [{"page_content": page.content, "metadata": {"title": page.title}}]
    except Exception as e:
        st.error(f"ìœ„í‚¤í”¼ë””ì•„ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return []
```

ì´ í•¨ìˆ˜ëŠ” ìœ„í‚¤í”¼ë””ì•„ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì£¼ì œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤:
- `@st.cache_data` ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìºì‹œí•©ë‹ˆë‹¤. ì´ëŠ” ë™ì¼í•œ ê²€ìƒ‰ì–´ì— ëŒ€í•œ ë°˜ë³µì ì¸ API í˜¸ì¶œì„ ë°©ì§€í•©ë‹ˆë‹¤.
- ê²€ìƒ‰ í”„ë¡œì„¸ìŠ¤ëŠ” ì—¬ëŸ¬ ë‹¨ê³„ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤:
  1. ì •í™•í•œ ì œëª© ë§¤ì¹˜ ì‹œë„
  2. ëª¨í˜¸ì„± í•´ê²° (DisambiguationError ì²˜ë¦¬)
  3. ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ê²½ìš° ìœ ì‚¬í•œ í˜ì´ì§€ ê²€ìƒ‰
- ê° ë‹¨ê³„ì—ì„œ ì˜ˆì™¸ë¥¼ ì²˜ë¦¬í•˜ì—¬ ê²¬ê³ ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤.
- ê²€ìƒ‰ ê²°ê³¼ë¥¼ í‘œì¤€í™”ëœ í˜•ì‹ (í˜ì´ì§€ ë‚´ìš©ê³¼ ë©”íƒ€ë°ì´í„°)ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.

## 7. í€´ì¦ˆ ìƒì„± ì—”ì§„

```python
@st.cache_data(show_spinner="í€´ì¦ˆ ë§Œë“œëŠ” ì¤‘...")
def run_quiz_chain(_docs, topic, _llm, difficulty):
    if not isinstance(_docs, list) or len(_docs) == 0:
        return {"questions": []}

    formatted_docs = format_docs(_docs)

    questions_chain = {
        "context": lambda x: formatted_docs,
        "difficulty": lambda x: difficulty
    } | questions_prompt | _llm
    formatting_chain = formatting_prompt | _llm
    chain = {"context": questions_chain} | formatting_chain | output_parser
    return chain.invoke(formatted_docs)
```

ì´ í•¨ìˆ˜ëŠ” LangChainì„ ì‚¬ìš©í•˜ì—¬ í€´ì¦ˆ ìƒì„± í”„ë¡œì„¸ìŠ¤ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤:
- `@st.cache_data` ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë™ì¼í•œ ì…ë ¥ì— ëŒ€í•œ í€´ì¦ˆ ìƒì„± ê²°ê³¼ë¥¼ ìºì‹œí•©ë‹ˆë‹¤.
- ì…ë ¥ ê²€ì¦ì„ ìˆ˜í–‰í•˜ì—¬ ë¹ˆ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ì— ëŒ€í•´ ë¹ˆ í€´ì¦ˆë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
- `format_docs` í•¨ìˆ˜(ë³„ë„ ì •ì˜ í•„ìš”)ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œë¥¼ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
- LangChainì˜ ì²´ì¸ ê°œë…ì„ ì‚¬ìš©í•˜ì—¬ í€´ì¦ˆ ìƒì„± í”„ë¡œì„¸ìŠ¤ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤:
  1. `questions_chain`: ë¬¸ë§¥ê³¼ ë‚œì´ë„ë¥¼ ê³ ë ¤í•˜ì—¬ ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
  2. `formatting_chain`: ìƒì„±ëœ ì§ˆë¬¸ì„ êµ¬ì¡°í™”ëœ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
  3. `output_parser`: ìµœì¢… ì¶œë ¥ì„ íŒŒì‹±í•˜ì—¬ ì‚¬ìš©