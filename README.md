# Document GPT

Document GPTëŠ” Streamlitì„ ì´ìš©í•´ ë§Œë“  ëŒ€í™”í˜• ë¬¸ì„œ ë¶„ì„ ì• í”Œë¦¬ì¼€ì´ì…˜ì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ AIì—ê²Œ ì§ˆë¬¸í•˜ê³  ë‹µë³€ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ê¸°ëŠ¥

1. **í™ˆ í˜ì´ì§€**
   - ì• í”Œë¦¬ì¼€ì´ì…˜ì— ëŒ€í•œ ê¸°ë³¸ ì•ˆë‚´ ì œê³µ
   - ì†ŒìŠ¤ ì½”ë“œ í™•ì¸ ì˜µì…˜

2. **Document GPT í˜ì´ì§€**
   - OpenAI API í‚¤ ì…ë ¥ ë° ìœ íš¨ì„± ê²€ì¦
   - ë¬¸ì„œ ì—…ë¡œë“œ (.txt, .pdf, .docx, .md íŒŒì¼ ì§€ì›)
   - ì—…ë¡œë“œëœ ë¬¸ì„œì— ëŒ€í•´ AIì—ê²Œ ì§ˆë¬¸í•˜ê³  ë‹µë³€ ë°›ê¸°

## ì„¤ì¹˜ ë° ì‹¤í–‰

1. ì €ì¥ì†Œë¥¼ í´ë¡ í•©ë‹ˆë‹¤:
   ```
   git clone [ì €ì¥ì†Œ URL]
   cd [í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬]
   ```

2. í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤:
   ```
   pip install -r requirements.txt
   ```

3. Streamlit ì•±ì„ ì‹¤í–‰í•©ë‹ˆë‹¤:
   ```
   streamlit run app.py
   ```

## íŒŒì¼ êµ¬ì¡°

```
.
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ app.py
â”œâ”€â”€ pages
â”‚   â””â”€â”€ Document_gpt.py
â””â”€â”€ requirements.txt
```

- `app.py`: ë©”ì¸ Streamlit ì• í”Œë¦¬ì¼€ì´ì…˜ íŒŒì¼
- `pages/Document_gpt.py`: Document GPT ê¸°ëŠ¥ì„ êµ¬í˜„í•œ í˜ì´ì§€
- `requirements.txt`: í”„ë¡œì íŠ¸ ì˜ì¡´ì„± ëª©ë¡

## ì‚¬ìš© ë°©ë²•

1. OpenAI API í‚¤ë¥¼ ì‚¬ì´ë“œë°”ì— ì…ë ¥í•©ë‹ˆë‹¤.
2. ë¶„ì„í•˜ê³ ì í•˜ëŠ” ë¬¸ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤.
3. ë¬¸ì„œì— ëŒ€í•´ ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ AIê°€ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.

## ì£¼ì˜ì‚¬í•­

- OpenAI API í‚¤ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì— ì €ì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
- ì§€ì›ë˜ëŠ” íŒŒì¼ í˜•ì‹: .txt, .pdf, .docx, .md


# ì²¨ë¶€ : Document_gpt.py ì½”ë“œ ì„¤ëª…

## ëª©ì°¨
1. [ê°œìš”](#ê°œìš”)
2. [ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸](#ë¼ì´ë¸ŒëŸ¬ë¦¬-ì„í¬íŠ¸)
3. [Streamlit í˜ì´ì§€ ì„¤ì •](#streamlit-í˜ì´ì§€-ì„¤ì •)
4. [ChatCallbackHandler í´ë˜ìŠ¤](#chatcallbackhandler-í´ë˜ìŠ¤)
5. [OpenAI ëª¨ë¸ ì´ˆê¸°í™”](#openai-ëª¨ë¸-ì´ˆê¸°í™”)
6. [íŒŒì¼ ì„ë² ë”©](#íŒŒì¼-ì„ë² ë”©)
7. [ë©”ì‹œì§€ ê´€ë¦¬ í•¨ìˆ˜](#ë©”ì‹œì§€-ê´€ë¦¬-í•¨ìˆ˜)
8. [í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿](#í”„ë¡¬í”„íŠ¸-í…œí”Œë¦¿)
9. [API í‚¤ ê²€ì¦](#api-í‚¤-ê²€ì¦)
10. [ë©”ì¸ UI êµ¬ì„±](#ë©”ì¸-ui-êµ¬ì„±)
11. [ë©”ì¸ ë¡œì§](#ë©”ì¸-ë¡œì§)
12. [ê²°ë¡ ](#ê²°ë¡ )

## ê°œìš”

ì´ ì½”ë“œëŠ” Streamlitì„ ì‚¬ìš©í•˜ì—¬ ë§Œë“  "Document GPT"ë¼ëŠ” ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì…ë‹ˆë‹¤. ì´ ì• í”Œë¦¬ì¼€ì´ì…˜ì€ ì‚¬ìš©ìê°€ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  í•´ë‹¹ ë¬¸ì„œì— ëŒ€í•´ ì§ˆë¬¸ì„ í•  ìˆ˜ ìˆê²Œ í•´ì£¼ë©°, OpenAIì˜ APIë¥¼ í™œìš©í•˜ì—¬ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.

## ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸

```python
import os
import requests
from langchain.prompts import ChatPromptTemplate
from langchain.document_loaders import UnstructuredFileLoader
from langchain.embeddings import CacheBackedEmbeddings, OpenAIEmbeddings
from langchain.schema.runnable import RunnableLambda, RunnablePassthrough
from langchain.storage import LocalFileStore
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores.faiss import FAISS
from langchain.chat_models import ChatOpenAI
from langchain.callbacks.base import BaseCallbackHandler
import streamlit as st
```

ì´ ì„¹ì…˜ì—ì„œëŠ” í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ì„í¬íŠ¸í•©ë‹ˆë‹¤. ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œëŠ”:
- Streamlit: ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ì¶•
- LangChain: AI ëª¨ë¸ì„ ì‰½ê²Œ í™œìš©í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” í”„ë ˆì„ì›Œí¬
- Requests: HTTP ìš”ì²­ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬

## Streamlit í˜ì´ì§€ ì„¤ì •

```python
st.set_page_config(
    page_title="Document GPT",
    page_icon="ğŸ“„",
    layout="wide",
)
```

Streamlit ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ê¸°ë³¸ ì„¤ì •ì„ ì •ì˜í•©ë‹ˆë‹¤:
- í˜ì´ì§€ ì œëª©: "Document GPT"
- í˜ì´ì§€ ì•„ì´ì½˜: ğŸ“„ (ë¬¸ì„œ ì´ëª¨ì§€)
- ë ˆì´ì•„ì›ƒ: "wide" (ì „ì²´ í™”ë©´ ë„ˆë¹„ ì‚¬ìš©)

## ChatCallbackHandler í´ë˜ìŠ¤

```python
class ChatCallbackHandler(BaseCallbackHandler):
    message = ""

    def on_llm_start(self, *args, **kwargs):
        self.message_box = st.empty()

    def on_llm_end(self, *args, **kwargs):
        save_message(self.message, "ai")

    def on_llm_new_token(self, token, *args, **kwargs):
        self.message += token
        self.message_box.markdown(self.message)
```

ì´ í´ë˜ìŠ¤ëŠ” OpenAIì˜ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ì‹¤ì‹œê°„ìœ¼ë¡œ í™”ë©´ì— í‘œì‹œí•˜ê¸° ìœ„í•œ ì½œë°± í•¸ë“¤ëŸ¬ì…ë‹ˆë‹¤:
- `on_llm_start`: ì‘ë‹µ ì‹œì‘ ì‹œ ë¹ˆ ë©”ì‹œì§€ ë°•ìŠ¤ ìƒì„±
- `on_llm_end`: ì‘ë‹µ ì™„ë£Œ ì‹œ ë©”ì‹œì§€ ì €ì¥
- `on_llm_new_token`: ìƒˆ í† í° ìˆ˜ì‹  ì‹œ ë©”ì‹œì§€ ë°•ìŠ¤ ì—…ë°ì´íŠ¸

## OpenAI ëª¨ë¸ ì´ˆê¸°í™”

```python
@st.cache_resource
def get_openai_model(api_key):
    return ChatOpenAI(
        temperature=0.1,
        streaming=True,
        callbacks=[ChatCallbackHandler()],
        openai_api_key=api_key,
    )
```

ì´ í•¨ìˆ˜ëŠ” OpenAI ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤:
- `@st.cache_resource`: ë¦¬ì†ŒìŠ¤ ìºì‹±ì„ ìœ„í•œ Streamlit ë°ì½”ë ˆì´í„°
- Temperature 0.1: ë‚®ì€ ë¬´ì‘ìœ„ì„±
- Streaming: ì‹¤ì‹œê°„ ì‘ë‹µì„ ìœ„í•œ ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”
- Callbacks: ì‹¤ì‹œê°„ ì‘ë‹µ í‘œì‹œë¥¼ ìœ„í•œ ì½œë°± í•¸ë“¤ëŸ¬ ì‚¬ìš©

## íŒŒì¼ ì„ë² ë”©

```python
@st.cache_data(show_spinner="Embedding File...")
def embed_file(file, api_key):
    # ... (íŒŒì¼ ì½ê¸° ë° ì €ì¥)
    # ... (í…ìŠ¤íŠ¸ ë¶„í• )
    # ... (ì„ë² ë”© ìƒì„±)
    # ... (ë²¡í„° ì €ì¥ì†Œ ìƒì„±)
    return retriever
```

ì´ í•¨ìˆ˜ëŠ” ì—…ë¡œë“œëœ íŒŒì¼ì„ ì²˜ë¦¬í•˜ê³  ì„ë² ë”©í•©ë‹ˆë‹¤:
- íŒŒì¼ ì½ê¸° ë° ë¡œì»¬ ì €ì¥
- í…ìŠ¤íŠ¸ ë¶„í• 
- OpenAI ì„ë² ë”© ìƒì„±
- FAISS ë²¡í„° ì €ì¥ì†Œ ìƒì„±
- ê²€ìƒ‰ê¸°(retriever) ë°˜í™˜

## ë©”ì‹œì§€ ê´€ë¦¬ í•¨ìˆ˜

```python
def save_message(message, role):
    st.session_state["messages"].append({"message": message, "role": role})

def send_message(message, role, save=True):
    with st.chat_message(role):
        st.markdown(message)
    if save:
        save_message(message, role)

def paint_history():
    for message in st.session_state["messages"]:
        send_message(message["message"], message["role"], save=False)
```

ì´ í•¨ìˆ˜ë“¤ì€ ì±„íŒ… íˆìŠ¤í† ë¦¬ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤:
- `save_message`: ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
- `send_message`: ë©”ì‹œì§€ë¥¼ í™”ë©´ì— í‘œì‹œí•˜ê³  ì„ íƒì ìœ¼ë¡œ ì €ì¥
- `paint_history`: ì €ì¥ëœ ëª¨ë“  ë©”ì‹œì§€ë¥¼ í™”ë©´ì— ë‹¤ì‹œ í‘œì‹œ

## í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿

```python
prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            """
            Answer the question using ONLY the following context. If you don't know the answer just say you don't know. DON'T make anything up.

            Context: {context}
            """,
        ),
        ("human", "{question}"),
    ]
)
```

ì´ í…œí”Œë¦¿ì€ AIì—ê²Œ ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ì˜ êµ¬ì¡°ë¥¼ ì •ì˜í•©ë‹ˆë‹¤:
- ì‹œìŠ¤í…œ ë©”ì‹œì§€: AIì—ê²Œ ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ë„ë¡ ì§€ì‹œ
- ì¸ê°„ ë©”ì‹œì§€: ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ í¬í•¨

## API í‚¤ ê²€ì¦

```python
def is_valid_api_key(api_key):
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    try:
        response = requests.get(
            "https://api.openai.com/v1/models", headers=headers)
        return response.status_code == 200
    except requests.RequestException:
        return False
```

ì´ í•¨ìˆ˜ëŠ” ì œê³µëœ OpenAI API í‚¤ì˜ ìœ íš¨ì„±ì„ ê²€ì‚¬í•©ë‹ˆë‹¤:
- OpenAI APIì— ìš”ì²­ì„ ë³´ë‚´ ì‘ë‹µ ìƒíƒœ ì½”ë“œ í™•ì¸
- ì˜ˆì™¸ ì²˜ë¦¬ë¥¼ í†µí•œ ì•ˆì •ì„± í™•ë³´

## ë©”ì¸ UI êµ¬ì„±

```python
st.title("ğŸ“„ Document GPT")

st.markdown("í™˜ì˜í•©ë‹ˆë‹¤!<br>ì´ ì±—ë´‡ì„ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ì„ ì—…ë¡œë“œ í•˜ê³  AIì—ê²Œ ì§ˆë¬¸í•˜ì„¸ìš”!<br>ì‚¬ì´ë“œ ë°”ì— API í‚¤ë¥¼ ì…ë ¥í•˜ê³  íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”!<br>API í‚¤ëŠ” ì €ì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
            unsafe_allow_html=True)

with st.sidebar:
    api_key = st.text_input("OpenAI API Key", type="password")
    file = st.file_uploader("Upload a .txt, .pdf, .docs, .md files only", type=[
                            "pdf", "txt", "docx", "md"])
```

ë©”ì¸ UI êµ¬ì„±:
- ì• í”Œë¦¬ì¼€ì´ì…˜ ì œëª©
- ì‚¬ìš© ì•ˆë‚´ ë©”ì‹œì§€
- ì‚¬ì´ë“œë°”: API í‚¤ ì…ë ¥ í•„ë“œì™€ íŒŒì¼ ì—…ë¡œë”

## ë©”ì¸ ë¡œì§

```python
if api_key:
    if is_valid_api_key(api_key):
        os.environ["OPENAI_API_KEY"] = api_key
        st.success("API í‚¤ê°€ ìœ íš¨í•©ë‹ˆë‹¤.")

        if file:
            retriever = embed_file(file, api_key)
            llm = get_openai_model(api_key)
            send_message("Good! Ask Anything!", "ai", save=False)
            paint_history()
            message = st.chat_input("Ask Anything! about your file...")
            if message:
                send_message(message, "human")
                chain = ({
                    "context": retriever | RunnableLambda(format_docs),
                    "question": RunnablePassthrough(),
                } | prompt | llm)
                with st.chat_message("ai"):
                    chain.invoke(message)
        else:
            st.warning("Please upload a file in the sidebar.")
    else:
        st.error("Invalid API key. Please check your OpenAI API key and try again.")
elif not api_key:
    st.warning("Please enter your OpenAI API key in the sidebar.")
```

ë©”ì¸ ë¡œì§:
1. API í‚¤ ìœ íš¨ì„± ê²€ì‚¬
2. íŒŒì¼ ì—…ë¡œë“œ í™•ì¸
3. íŒŒì¼ ì„ë² ë”© ë° OpenAI ëª¨ë¸ ì´ˆê¸°í™”
4. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
5. AI ì‘ë‹µ ìƒì„± ë° í‘œì‹œ

## ê²°ë¡ 

ì´ Document GPT ì• í”Œë¦¬ì¼€ì´ì…˜ì€ Streamlitê³¼ LangChainì„ í™œìš©í•˜ì—¬ ë³µì¡í•œ AI ê¸°ëŠ¥ì„ ê°„ë‹¨í•œ ì›¹ ì¸í„°í˜ì´ìŠ¤ë¡œ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤. ì£¼ìš” íŠ¹ì§•ìœ¼ë¡œëŠ” ì‹¤ì‹œê°„ ì‘ë‹µ, ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸ë‹µë³€, API í‚¤ ë³´ì•ˆ, ê·¸ë¦¬ê³  íš¨ìœ¨ì ì¸ íŒŒì¼ ì²˜ë¦¬ê°€ ìˆìŠµë‹ˆë‹¤. ì´ ì• í”Œë¦¬ì¼€ì´ì…˜ì€ ì‚¬ìš©ì ì¹œí™”ì ì¸ ì¸í„°í˜ì´ìŠ¤ì™€ ê°•ë ¥í•œ AI ê¸°ëŠ¥ì„ ê²°í•©í•˜ì—¬ ë¬¸ì„œ ë¶„ì„ ë° ì •ë³´ ì¶”ì¶œ ì‘ì—…ì„ íš¨ê³¼ì ìœ¼ë¡œ ìˆ˜í–‰í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.